---
title: "Class activity"
output: 
  rmdformats::robobook:
    css: "homework.css"
    highlight: pygments
link-citations: yes
---

# Generalized estimating equations

Generalized estimating equations are an alternative to mixed effects models for handling correlated/clustered data. In this class activity, we will work with generalized estimating equations for linear models, which end up behaving very similarly to linear mixed effects models. (The main difference is the use of a robust sandwich estimator for the variance).

Let $Y_i = (Y_{i,1},...,Y_{i, n_i})^T$ be the vector of responses for group $i$ in the data, and $X_i$ the design matrix for group $i$. The linear GEE assumes that $\mathbb{E}[Y_i] = X_i \beta$, and $Var(Y_i) = V_i$. If we don't want to assume the observations are independent, a common form for $V_i$ is 

$$V_i = \sigma^2 \begin{bmatrix} 1 & \rho & \rho & \cdots & \rho \\ \rho & 1 & \rho & \cdots & \rho \\ \vdots & \vdots & \vdots & \cdots & \vdots \\ \rho & \rho & \rho & \cdots & 1 \end{bmatrix}$$

This is the *exchangeable* covariance structure. 

The coefficients $\beta$ are estimated by solving

$$\sum \limits_{i=1}^m X_i^T V_i^{-1}(Y_i - X_i \beta) = 0$$
Because $\sigma^2$ and $\rho$ are typically unknown, $\beta$ and $\sigma^2$ and $\rho$ are typically optimized simultaneously in an iterative algorithm similar to Fisher scoring.

Given $\widehat{\beta}$, the estimates for $\sigma^2$ and $\sigma^2 \rho$ are

$$\widehat{\sigma}^2 = \frac{1}{N - p} \sum \limits_{i=1}^m \sum \limits_{j=1}^{n_i} e_{ij}^2$$

$$\widehat{\sigma}^2 \widehat{\rho} = \frac{1}{m} \sum \limits_{i=1}^m \frac{1}{n_i(n_i - 1)} \sum \limits_{j\neq k} e_{ij} e_{ik}$$

where $e_{ij} = Y_{ij} - X_{ij}^T \widehat{\beta}$.

The estimated variance of $\widehat{\beta}$ is given by the sandwich variance matrix

$$\widehat{Var}(\widehat{\beta}) = \widehat{A}^{-1} \widehat{B} \widehat{A}^{-1},$$

where $\widehat{A} = \sum \limits_{i=1}^m X_i^T \widehat{V}_i^{-1} X_i$ and 

$$\widehat{B} = \sum \limits_{i=1}^m X_i^T \widehat{V}_i^{-1}(Y_i - X_i \widehat{\beta}) (Y_i - X_i \widehat{\beta})^T \widehat{V}_i^{-1} X_i$$

## Simulating data

Let's simulate data from a model with a random intercept (which, as we have seen, is equivalent to an exchangeable correlation structure):

```{r, eval=F}
m <- 10
n_i <- 10
n <- m*n_i
groups <- rep(1:m, each=n_i)
sigma_u <- 0.5
sigma_e <- 0.5

u <- rnorm(m, sd=sigma_u)
x1 <- rnorm(n)
x2 <- rnorm(m)[groups]
y <- 1 + u[groups] + 0*x1 + 1*x2 + rnorm(n, sd=sigma_e)
```


:::{.question}
#### Question 1

Use the following code to fit the GEE, and report the estimated coefficients:

```{r, eval=F}
library(gee)

m1 <- gee(y ~ x1 + x2, id = groups, corstr = "exchangeable")
```

:::


:::{.question}
#### Question 2

The estimate $\widehat{\sigma}^2$ is stored in `m1$scale`, and the estimated correlation $\widehat{\rho}$ is stored in `m1$working.correlation`. Calculate these parameter estimates using the equations above, and verify that they agree with the R output.

:::


:::{.question}
#### Question 3

$\widehat{A}^{-1}$, part of the robust sandwich variance for $\widehat{\beta}$, is stored in `m1$naive.variance`. Calculate $\widehat{A}^{-1}$ using the equations above, and verify that your estimate agrees with the R output.

:::

:::{.question}
#### Question 4

The full robust sandwich variance for $\widehat{\beta}$ is stored in `m1$robust.variance`. Calculate $\widehat{A}^{-1} \widehat{B} \widehat{A}^{-1}$ using the equations above, and verify that your estimate agrees with the R output.

:::



## Simulations

Suppose we want to test $H_0: \beta_1 = 0$ vs. $H_A: \beta_1 \neq 0$. The p-value for this test (using the robust sandwich variance) can be obtained from the fitted GEE model by

```{r, eval=F}
2*pnorm(abs(summary(m1)$coefficients[2,5]), lower.tail=F)
```

:::{.question}
#### Question 5

Simulate data many times, with $H_0: \beta_1 = 0$ true in each simulation. Test the hypothesis and record the p-value for each simulated dataset. Do you approximately control the type I error rate at level 0.05?

:::

:::{.question}
#### Question 6

Does type I error control depend on the number of groups ($m$), or the number of observations within each group ($n_i$)?

:::